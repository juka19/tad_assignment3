---
title: "Congress text mining"
title-slide-attributes:
    data-background-image: /layout/background.jpg
    title-slide-style: 
subtitle: "Text as Data Assignment 3"
date: 01.12.2022
format:
    revealjs:
        code-fold: true
        code-tools: true
        theme: sky
        slide-number: true
        preview-links: auto
        footer: "[github.com/juka19/tad_assignment3](https://github.com/juka19/tad_assignment3)"
        transition: slide
        transition-speed: fast
        background-transition: fade
filters:
    - reveal-auto-agenda
    - designmode
auto-agenda:
    bullets: numbered
    heading: Agenda
auto-play-media: true
jupyter: python3
---

# Research question

::: columns
::: {.column width="80%"}
-   between 2016 and 2022 there have been major shifts in terms of majorities in the US congress:

    -   in 2016, both chambers were hold by Republicans

    -   in 2018, the Democrats gained a majority in Congress

    -   in 2020 the Democrats gained Congress and Senate

-   While one might expect that the post 2016 and 2020 congresses will vary in their topics and policies. However, it is interesting to also focus on the period between 2018 and 2020: When both chambers had different majorities and needed to cooperate.

-   We will focus on the question on whether and how the different majorities had an impact on the policies that have been passed by Congress.
:::

::: {.column width="20%"}
![](https://www.politico.com/dims4/default/0ba7efa/2147483647/strip/true/crop/1160x773+0+0/resize/1290x860!/quality/90/?url=https%253A%252F%252Fstatic.politico.com%252Fa3%252F2c%252Ffbd235e445b4a96e0373e3060e3c%252Fgettyimages-1294351903-1.jpg){width="300"}
:::
:::

# Data acquisition & preprocessing

## Overview

-   Data from the 115^th^, 116^th^ and 117^th^ US congress
-   Text summaries of public laws
-   Metadata
    -   sponsors, cosponsors, actions, policy fields, ...

## Data acquisition

::: panel-tabset
### Challenges

-   Paginated output
-   Multiple API calls for each observation
-   Request limit of 1000 API calls per hour

[Not knowing about bulk download options of ProRepublica... {{< fa regular face-rolling-eyes >}}]{.fragment}

### Code

``` python
@congress_deco(output_format='json')
def get_congress_data(query:str, *args, api_key=os.getenv('US.GOV_API')) -> dict:
        
        hdr = {
                # specifying requested encoding
                'Cache-Control': 'no-cache',
                'charset': 'UTF-8',
                'X-Api-Key': api_key,
                'User-Agent': random.choice(['Mozilla/5.0', 'Chrome 104.0.0.0', 
                                                'Chrome 52.0.2762.73', 'Chrome 55.0.2919.83'])
                }
        
        BASE_URL = 'https://api.congress.gov/v3/'
        
        query_url = BASE_URL + query
        
        if args: # concatenate variable arguments to url
                query_url += '&' + '&'.join(args)
                        
        return (query_url, hdr)
```
:::

## Data

## Share of Cosponsors across Policy fields

```{python, fullscreen=true}
import plotly.io as pio
fig = pio.read_json('plots\\polar_line_plot')
fig.show()
```

## Preprocessing

# Methods

# Results

# Discussion

# Conclusion
